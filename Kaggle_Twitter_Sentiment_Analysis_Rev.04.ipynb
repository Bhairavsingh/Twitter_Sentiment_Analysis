{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading required libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "#Loading nltk library and its packages for text processing.\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Downloading some necessary word lists.\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "#Downloading all dependencies and corpora.\n",
    "#nltk.download()\n",
    "#nltk.download('all', halt_on_error=False)\n",
    "\n",
    "#Importing pattern and its dependencies.\n",
    "import pattern\n",
    "from pattern.en import tag\n",
    "from pattern.en import parse\n",
    "from pattern.en import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Training and Testing Datasets.\n",
    "raw_data = pd.read_csv(\"C:/Users/Bhair/OneDrive - University of Oklahoma/Master_of_Science_Data/Data Science Practice/Twitter Sentiment Analysis/Data/tweet-sentiment-extraction/train.csv\")\n",
    "#test_data = pd.read_csv(\"C:/Users/Bhair/OneDrive - University of Oklahoma/Master_of_Science_Data/Data Science Practice/Twitter Sentiment Analysis/Data/tweet-sentiment-extraction/test.csv\")\n",
    "\n",
    "\n",
    "\n",
    "#Contraction directory.\n",
    "\n",
    "CONTRACTION_MAP = {\n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "#Customized stop words.\n",
    "stop_words = {'a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', \n",
    "              'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \n",
    "              'doing', 'don', 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'he', 'her', 'here', \n",
    "              'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'it', \"it's\", 'its', \n",
    "              'itself', 'just', 'm', 'ma', 'me', 'more', 'most', 'my', 'myself', 'now', 'o', 'of', 'off', 'on', \n",
    "              'once', 'only', 'or', 'other', 'our',  'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', \n",
    "              'shan', \"shan't\", 'she', \"she's\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', \n",
    "              'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', \n",
    "              'too', 'under', 'until', 'up', 've', 'very', 'we', 'while', 'with', 'y', 'you', \"you'd\", \"you'll\", \n",
    "              \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves'}\n",
    "\n",
    "\n",
    "\n",
    "#Function for expanding contractions using above dictonary of contractions.\n",
    "def expand_contractions(sentence, contraction_mapping):\n",
    "    #Creating a list of contraction keys.\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())),\n",
    "                                      flags = re.IGNORECASE|re.DOTALL)\n",
    "    \n",
    "    #Function for expanding the contractions.\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = (contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower()))\n",
    "        expanded_contraction = first_char + expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "    expanded_sentence = contractions_pattern.sub(expand_match, sentence)\n",
    "    return expanded_sentence\n",
    "\n",
    "\n",
    "\n",
    "#Function for creating a list ofstrings from the input. It creates different elements in the list if there is a space.\n",
    "#Basically, a sentence will be converted into a list of words.\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "#Reading the file with vocabulary.\n",
    "WORDS = Counter(words(open('C:/Users/Bhair/OneDrive - University of Oklahoma/Master_of_Science_Data/Data Science Practice/Twitter Sentiment Analysis/big.txt').read()))\n",
    "\n",
    "#Function for calculating probability of the given word to find in the vocabulary.\n",
    "def P(word, N = sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    #WORDS[word] gives the count of word\n",
    "    #N is total number of words in the vocabulary.\n",
    "    return WORDS[word] / N\n",
    "\n",
    "#Main function which should be called for word correction.\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key = P)\n",
    "\n",
    "#Function for genetraing all possible real words from given string.\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "#Function for editing given string. This returns words which are one edit away from input string.\n",
    "#The function edits1 returns a set of all the edited strings (whether words or not) that can be made with one simple edit: \n",
    "#a simple edit to a word is a deletion (remove one letter), a transposition (swap two adjacent letters), a replacement (change one letter to another) or an insertion (add a letter).\n",
    "#The output of this function can be a big set. For a word of length n, there will be n deletions, n-1 transpositions, \n",
    "#26n alterations, and 26(n+1) insertions, for a total of 54n+25 (of which a few are typically duplicates)\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    #Splitting the letters of a word to form a combination.\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "#Function for generating set of words which are two edits away from input string.\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "\n",
    "#Function for converting a list to a string.\n",
    "def listToString(inlist):\n",
    "    #Initialize an empty string.\n",
    "    string = \" \"\n",
    "    return (string.join(inlist))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Function for preprocessing and normalizing text data.\n",
    "def data_normalization(indata):\n",
    "    #Setting stop word variable using NLTK package.\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    \n",
    "    #Creating list of punctuations.\n",
    "    punctuations = [\".\", \",\", \"!\", \"`\", \"...\", \"****\", \":\", \"(\", \")\", \"?\", \"-\", \"{\", \"}\", \"[\", \"]\", \";\", \"/\", \"+\", \"<\", \n",
    "               \">\", \"|\", \"=\" \"_\", \"^\", \"@\", \"#\", \"$\", \"%\", \"~\", \"'\", \"..\"]\n",
    "    \n",
    "    #Regular expression tokenizer with only alphanumeric contents.\n",
    "    Token_Pattern = r'\\w+'\n",
    "    regex_wt = nltk.RegexpTokenizer(pattern = Token_Pattern, gaps = False)\n",
    "\n",
    "    #Listing out all contractions.\n",
    "    contaction_keys = list(CONTRACTION_MAP.keys())\n",
    "\n",
    "    #Declaring list for storing lemmatized tweets.\n",
    "    lemmatized_words = []\n",
    "    for i in range(len(indata)):\n",
    "        #Condition for empty tweets.\n",
    "        if (str(indata[i]) == \"nan\"):\n",
    "            #Fake strink in the blank tweet.\n",
    "            indata[i] = \"NA\"\n",
    "        #Expanding contractions.\n",
    "        text_segment = indata[i].replace(\"`\", \"'\")\n",
    "        expanded_tweets = expand_contractions(text_segment, CONTRACTION_MAP)\n",
    "        #Removing URL links from tweets.\n",
    "        expanded_tweets = re.sub(r'http\\S+', '', expanded_tweets, flags = re.MULTILINE)\n",
    "        #print(\"After contractions: \", expanded_tweets)\n",
    "        #Tokenizing the words.\n",
    "        tokens = regex_wt.tokenize(expanded_tweets)\n",
    "        #Declaring list for lemmatized words.\n",
    "        lemm_list = []\n",
    "        for word in tokens:\n",
    "            #Condition for stopwords.\n",
    "            #if (word not in stopWords):\n",
    "            if (word not in stop_words):\n",
    "                #Condition for punctuations.\n",
    "                if (word not in punctuations):\n",
    "                    #Correcting the word.\n",
    "                    #Not using this function because its not correcting words properly. Need to find more accurate way!\n",
    "                    #corrected_spell = correction(word)\n",
    "                    corrected_spell = word\n",
    "                    #Converting all letters to lower form.\n",
    "                    corrected_spell = corrected_spell.lower()\n",
    "                    #Lemmatizing words.\n",
    "                    lemm_list.append(wordnet_lemmatizer.lemmatize(corrected_spell, pos = \"v\"))\n",
    "        #Converting the lemmatized word's (document) list to a string.\n",
    "        lemm_string = listToString(lemm_list)\n",
    "        lemmatized_words.append(lemm_string)\n",
    "    return lemmatized_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for extracting features from given data. There are three options of extraction methods are given:\n",
    "#Those are Bag of Words-based frequencies, occurrences, and TF-IDF based features\n",
    "def build_feature_matrix(documents, feature_type='frequency', ngram_range=(1, 1), min_df=0.0, max_df=1.0):\n",
    "    feature_type = feature_type.lower().strip()\n",
    "    if feature_type == 'binary':\n",
    "        vectorizer = CountVectorizer(binary=True, min_df=min_df, max_df=max_df, ngram_range=ngram_range)\n",
    "    \n",
    "    elif feature_type == 'frequency':\n",
    "        vectorizer = CountVectorizer(binary=False, min_df=min_df, max_df=max_df, ngram_range=ngram_range)\n",
    "    \n",
    "    elif feature_type == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df, ngram_range=ngram_range)\n",
    "    \n",
    "    else:\n",
    "        raise Exception(\"Wrong feature type entered. Possible values: 'binary', 'frequency', 'tfidf'\")\n",
    "    \n",
    "    feature_matrix = vectorizer.fit_transform(documents).astype(float)\n",
    "    return (vectorizer, feature_matrix)\n",
    "\n",
    "\n",
    "#Function for the model accuracy, precision, recall, and F1-score.\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    print('Accuracy:', np.round(metrics.accuracy_score(true_labels, predicted_labels), 2))\n",
    "    print('Precision:', np.round(metrics.precision_score(true_labels, predicted_labels, average='weighted'), 2))\n",
    "    print('Recall:', np.round(metrics.recall_score(true_labels, predicted_labels, average='weighted'), 2))\n",
    "    print('F1 Score:', np.round(metrics.f1_score(true_labels, predicted_labels, average='weighted'), 2))\n",
    "\n",
    "\n",
    "#Function for building the confusion matrix for evaluating the model predictions against the actual sentiment \n",
    "#labels for the tweets.\n",
    "def display_confusion_matrix(true_labels, predicted_labels):\n",
    "    cm = metrics.confusion_matrix(y_true = true_labels, y_pred = predicted_labels)\n",
    "    cm_frame = pd.DataFrame(cm)\n",
    "    print(cm_frame)\n",
    "\n",
    "\n",
    "#Function for getting a detailed classification report per sentiment category (positive, neutral and negative) \n",
    "#by displaying the precision, recall, F1-score, and support (number of reviews) for each of the classes.\n",
    "def display_classification_report(true_labels, predicted_labels):\n",
    "    report = metrics.classification_report(y_true = true_labels, y_pred = predicted_labels)\n",
    "    print(report)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Raw tweets\n",
    "raw_tweets = raw_data['text']\n",
    "#Raw tweets to view.\n",
    "training_raw_tweets = np.array(raw_tweets[:27000])\n",
    "testing_raw_tweets = np.array(raw_tweets[27000:])\n",
    "\n",
    "#Normalizing tweets.\n",
    "normalized_tweets = data_normalization(raw_data['text'])\n",
    "\n",
    "#Splitting train and test tweets.\n",
    "train_tweets = np.array(normalized_tweets[:27000])\n",
    "test_tweets = np.array(normalized_tweets[27000:])\n",
    "\n",
    "#Splitting sentiment labels.\n",
    "labels = raw_data['sentiment']\n",
    "train_labels = np.array(labels[:27000])\n",
    "test_labels = np.array(labels[27000:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorizing training tweets.\n",
    "#Building vectorizer model on trainning tweets and extracting features for train tweets.\n",
    "vectorizer, train_features = build_feature_matrix(train_tweets, feature_type = 'tfidf', ngram_range = (1, 1), \n",
    "                                                  min_df = 0.0, max_df = 1.0)\n",
    "\n",
    "#Extracting features for test tweets\n",
    "test_features = vectorizer.transform(test_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i would have respond i be go\n",
      "  (0, 8809)\t0.31416420825794106\n",
      "  (0, 3170)\t0.19997868615838085\n",
      "  (0, 16410)\t0.7727597783541493\n",
      "  (0, 9459)\t0.26504438601206154\n",
      "  (0, 21540)\t0.4403443808356867\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_tweets[0])\n",
    "print(train_features[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building the SVM classification model.\n",
    "svm = SGDClassifier(loss = 'hinge')\n",
    "svm.fit(train_features, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:-\n",
      "back to work tomoo  day 1 of 5 it will bee.\n",
      "Actual Labeled Sentiment: neutral\n",
      "Predicted Sentiment: neutral \n",
      "\n",
      "Tweet:-\n",
      " Wow. That`s looks really good. I wish I had some. Was it good?\n",
      "Actual Labeled Sentiment: positive\n",
      "Predicted Sentiment: positive \n",
      "\n",
      "Tweet:-\n",
      "  i wasn`t able to go the conference.so I didn`t get the outline.. however I have been doing my own & it`s coming along.\n",
      "Actual Labeled Sentiment: neutral\n",
      "Predicted Sentiment: neutral \n",
      "\n",
      "Tweet:-\n",
      " I only came across viva la juicy on fri, no testers only body lotion in the store.... but i defo need to get it asap\n",
      "Actual Labeled Sentiment: neutral\n",
      "Predicted Sentiment: neutral \n",
      "\n",
      "Tweet:-\n",
      " Maybe because you got in 4 hours ago from an awesome night? Nah, that can`t be it.\n",
      "Actual Labeled Sentiment: neutral\n",
      "Predicted Sentiment: positive \n",
      "\n",
      "Tweet:-\n",
      " i miss you  when are you gonna be down in irvine again?? liz and i were just reminiscing about all our adventures.\n",
      "Actual Labeled Sentiment: negative\n",
      "Predicted Sentiment: negative \n",
      "\n",
      "Tweet:-\n",
      " : Yes, that`s what I was implying. Was a bit too subtle, as usual, I suppose.\n",
      "Actual Labeled Sentiment: neutral\n",
      "Predicted Sentiment: neutral \n",
      "\n",
      "Tweet:-\n",
      "_kat why not??  ****\n",
      "Actual Labeled Sentiment: neutral\n",
      "Predicted Sentiment: neutral \n",
      "\n",
      "Tweet:-\n",
      " So that is different than normal how?\n",
      "Actual Labeled Sentiment: neutral\n",
      "Predicted Sentiment: neutral \n",
      "\n",
      "Tweet:-\n",
      "received her first pressie. Happy happy.\n",
      "Actual Labeled Sentiment: positive\n",
      "Predicted Sentiment: positive \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Printing the sample tested tweets and predicitons.\n",
    "for i in range(10):\n",
    "    print('Tweet:-')\n",
    "    print(testing_raw_tweets[i])\n",
    "    print('Actual Labeled Sentiment:', test_labels[i])\n",
    "    doc_features = test_features[i]\n",
    "    predicted_sentiment = svm.predict(doc_features)[0]\n",
    "    print('Predicted Sentiment:', predicted_sentiment, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74\n",
      "Precision: 0.74\n",
      "Recall: 0.74\n",
      "F1 Score: 0.74\n"
     ]
    }
   ],
   "source": [
    "#Predicting the sentiments for entire test dataset.\n",
    "predicted_sentiments = svm.predict(test_features)\n",
    "get_metrics(true_labels = test_labels, predicted_labels = predicted_sentiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.64      0.66       116\n",
      "     neutral       0.73      0.77      0.75       211\n",
      "    positive       0.81      0.78      0.79       154\n",
      "\n",
      "    accuracy                           0.74       481\n",
      "   macro avg       0.74      0.73      0.73       481\n",
      "weighted avg       0.74      0.74      0.74       481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Binary\n",
    "#Displaying report.\n",
    "display_classification_report(true_labels = test_labels, predicted_labels = predicted_sentiments, classes = [1,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.60      0.63       116\n",
      "     neutral       0.71      0.78      0.74       211\n",
      "    positive       0.81      0.75      0.78       154\n",
      "\n",
      "    accuracy                           0.73       481\n",
      "   macro avg       0.73      0.71      0.72       481\n",
      "weighted avg       0.73      0.73      0.73       481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Frequency\n",
    "#Displaying report.\n",
    "display_classification_report(true_labels = test_labels, predicted_labels = predicted_sentiments, classes = [1,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.57      0.62       116\n",
      "     neutral       0.68      0.78      0.73       211\n",
      "    positive       0.79      0.73      0.76       154\n",
      "\n",
      "    accuracy                           0.71       481\n",
      "   macro avg       0.72      0.69      0.70       481\n",
      "weighted avg       0.72      0.71      0.71       481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tfid\n",
    "#Displaying report.\n",
    "display_classification_report(true_labels = test_labels, predicted_labels = predicted_sentiments, classes = [1,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Building Random Forest classification model.\n",
    "#rf = RandomForestClassifier(n_estimators = 1000)\n",
    "#, max_depth = 3\n",
    "#rf.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(train_features, train_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:-\n",
      "back to work tomoo  day 1 of 5 it will bee.\n",
      "Actual Labeled Sentiment: neutral\n",
      "Predicted Sentiment: neutral \n",
      "\n",
      "Tweet:-\n",
      " Wow. That`s looks really good. I wish I had some. Was it good?\n",
      "Actual Labeled Sentiment: positive\n",
      "Predicted Sentiment: positive \n",
      "\n",
      "Tweet:-\n",
      "  i wasn`t able to go the conference.so I didn`t get the outline.. however I have been doing my own & it`s coming along.\n",
      "Actual Labeled Sentiment: neutral\n",
      "Predicted Sentiment: neutral \n",
      "\n",
      "Tweet:-\n",
      " I only came across viva la juicy on fri, no testers only body lotion in the store.... but i defo need to get it asap\n",
      "Actual Labeled Sentiment: neutral\n",
      "Predicted Sentiment: negative \n",
      "\n",
      "Tweet:-\n",
      " Maybe because you got in 4 hours ago from an awesome night? Nah, that can`t be it.\n",
      "Actual Labeled Sentiment: neutral\n",
      "Predicted Sentiment: neutral \n",
      "\n",
      "Tweet:-\n",
      " i miss you  when are you gonna be down in irvine again?? liz and i were just reminiscing about all our adventures.\n",
      "Actual Labeled Sentiment: negative\n",
      "Predicted Sentiment: neutral \n",
      "\n",
      "Tweet:-\n",
      " : Yes, that`s what I was implying. Was a bit too subtle, as usual, I suppose.\n",
      "Actual Labeled Sentiment: neutral\n",
      "Predicted Sentiment: neutral \n",
      "\n",
      "Tweet:-\n",
      "_kat why not??  ****\n",
      "Actual Labeled Sentiment: neutral\n",
      "Predicted Sentiment: negative \n",
      "\n",
      "Tweet:-\n",
      " So that is different than normal how?\n",
      "Actual Labeled Sentiment: neutral\n",
      "Predicted Sentiment: neutral \n",
      "\n",
      "Tweet:-\n",
      "received her first pressie. Happy happy.\n",
      "Actual Labeled Sentiment: positive\n",
      "Predicted Sentiment: positive \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Printing the sample tested tweets and predicitons.\n",
    "for i in range(10):\n",
    "    print('Tweet:-')\n",
    "    print(testing_raw_tweets[i])\n",
    "    print('Actual Labeled Sentiment:', test_labels[i])\n",
    "    doc_features = test_features[i]\n",
    "    predicted_sentiment = mnb.predict(doc_features)[0]\n",
    "    print('Predicted Sentiment:', predicted_sentiment, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.55      0.58       116\n",
      "     neutral       0.63      0.69      0.66       211\n",
      "    positive       0.71      0.66      0.68       154\n",
      "\n",
      "    accuracy                           0.65       481\n",
      "   macro avg       0.65      0.64      0.64       481\n",
      "weighted avg       0.65      0.65      0.65       481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predicting the sentiments for entire test dataset.\n",
    "predicted_sentiments = mnb.predict(test_features)\n",
    "\n",
    "\n",
    "#Binary Random Forest.\n",
    "#Displaying report.\n",
    "display_classification_report(true_labels = test_labels, predicted_labels = predicted_sentiments, classes = [1,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Function for predicting tweet.\n",
    "def sentiment_detector(text, vectorizer_model, model):\n",
    "    #Normalizing the text.\n",
    "    normalized_text = data_normalization(text)\n",
    "    tweet = np.array(normalized_text)\n",
    "    print(tweet)\n",
    "    #Extracting features from tweet.\n",
    "    tweet_features = vectorizer_model.transform(tweet)\n",
    "    features = tweet_features\n",
    "    #Predicting using trained model.\n",
    "    prediction = model.predict(features)[0]\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pack be no fun good thing i have unite keep go still no fun']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text = ['Packing is no fun at all good thing I have the united on to keep me going... still no fun']\n",
    "sentiment_detector(text, vectorizer_model = vectorizer, model = svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1   2\n",
      "0  120   23  11\n",
      "1   24  163  24\n",
      "2    5   37  74\n",
      "    0    1    2\n",
      "0  74   37    5\n",
      "1  24  163   24\n",
      "2  11   23  120\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix.\n",
    "display_confusion_matrix(test_labels, predicted_sentiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for data preprocessing, splitting and normalization.\n",
    "#Inputs: raw list of tweets, percentage split of training, validation and testing set.\n",
    "def set_preperation(raw_data, trainset_ratio, valset_ratio, testset_ratio):\n",
    "    \n",
    "    raw_tweets = raw_data['text']\n",
    "    #Total number of observations.\n",
    "    total_set = len(raw_tweets)\n",
    "    #Splitting values.\n",
    "    trainset_len = round(total_set * (trainset_ratio/100))\n",
    "    valset_len = round(total_set * (valset_ratio/100))\n",
    "    testset_len = round(total_set * (testset_ratio/100))\n",
    "    \n",
    "    #Raw tweets to view.\n",
    "    training_raw_tweets = np.array(raw_tweets[: trainset_len])\n",
    "    val_raw_tweets = np.array(raw_tweets[trainset_len : (trainset_len + valset_len)])\n",
    "    testing_raw_tweets = np.array(raw_tweets[(trainset_len + valset_len) :])\n",
    "\n",
    "    #Normalizing tweets.\n",
    "    normalized_tweets = data_normalization(raw_data['text'])\n",
    "\n",
    "    #Splitting train and test tweets.\n",
    "    train_tweets = np.array(normalized_tweets[: trainset_len])\n",
    "    val_tweets = np.array(normalized_tweets[trainset_len : (trainset_len + valset_len)])\n",
    "    test_tweets = np.array(normalized_tweets[(trainset_len + valset_len) :])\n",
    "\n",
    "    #Splitting sentiment labels.\n",
    "    #labels = raw_data['sentiment']\n",
    "    labels = raw_data['user_verified']\n",
    "    train_labels = np.array(labels[: trainset_len])\n",
    "    val_labels = np.array(labels[trainset_len : (trainset_len + valset_len)])\n",
    "    test_labels = np.array(labels[(trainset_len + valset_len) :])\n",
    "    \n",
    "    return train_tweets, val_tweets, test_tweets, train_labels, val_labels, test_labels\n",
    "\n",
    "\n",
    "\n",
    "#Function for feature extraction from all three sets. Model is built on only training set.\n",
    "#Input: training, validation and testing set and feature_type (default 'binary').\n",
    "def feature_extraction(train_tweets, val_tweets, test_tweets, feature_type = 'binary'):\n",
    "    #Vectorizing training tweets.\n",
    "    #Building vectorizer model on trainning tweets and extracting features for train tweets.\n",
    "    vectorizer, train_features = build_feature_matrix(train_tweets, feature_type = feature_type, \n",
    "                                                      ngram_range = (1, 1), \n",
    "                                                      min_df = 0.0, max_df = 1.0)\n",
    "\n",
    "    #Extracting features for validation and test tweets\n",
    "    val_features = vectorizer.transform(val_tweets)\n",
    "    test_features = vectorizer.transform(test_tweets)\n",
    "    \n",
    "    return train_features, val_features, test_features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing and splitting the dataset.\n",
    "train_tweets, val_tweets, test_tweets, train_labels, val_labels, test_labels = set_preperation(raw_tweets, \n",
    "                                                                                               trainset_ratio = 80, \n",
    "                                                                                               valset_ratio = 10, \n",
    "                                                                                               testset_ratio = 10)\n",
    "\n",
    "#Extracting features.\n",
    "train_features, val_features, test_features = feature_extraction(train_tweets, val_tweets, test_tweets, \n",
    "                                                                 feature_type = 'binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the SVM classification model.\n",
    "svm = SGDClassifier(loss = 'hinge')\n",
    "svm.fit(train_features, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parfit.parfit as pf\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet']\n",
    "}\n",
    "\n",
    "svm = SGDClassifier(loss = 'hinge')\n",
    "paramGrid = ParameterGrid(grid)\n",
    "bestModel, bestScore, allModels, allScores = pf.bestFit(SGDClassifier(), paramGrid,\n",
    "                                                        train_features, train_labels, val_features, val_labels, \n",
    "                                                        metric = roc_auc_score, \n",
    "                                                        scoreLabel = \"AUC\")\n",
    "#bestScore = 'max',\n",
    "print(bestModel, bestScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74\n",
      "Precision: 0.74\n",
      "Recall: 0.74\n",
      "F1 Score: 0.74\n"
     ]
    }
   ],
   "source": [
    "get_metrics(test_labels, predicted_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
